// æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å·¥å…·
import { supabaseAdmin } from '@/lib/supabase'
import { getCache } from '@/lib/redis'

// æŸ¥è¯¢æ€§èƒ½ç›‘æ§
class QueryPerformanceMonitor {
  private static metrics: Map<string, {
    totalTime: number
    count: number
    errors: number
    lastExecution: number
  }> = new Map()

  static recordQuery(queryName: string, duration: number, success: boolean) {
    const existing = this.metrics.get(queryName) || {
      totalTime: 0,
      count: 0,
      errors: 0,
      lastExecution: 0
    }

    existing.totalTime += duration
    existing.count += 1
    existing.lastExecution = Date.now()
    
    if (!success) {
      existing.errors += 1
    }

    this.metrics.set(queryName, existing)

    // æ€§èƒ½è­¦å‘Š
    const avgTime = existing.totalTime / existing.count
    if (avgTime > 1000 && existing.count > 10) {
      console.warn(`ğŸŒ æ…¢æŸ¥è¯¢è­¦å‘Š: ${queryName} å¹³å‡è€—æ—¶ ${avgTime.toFixed(0)}ms`)
    }
  }

  static getMetrics() {
    const results: Array<{
      queryName: string
      avgTime: number
      totalQueries: number
      errorRate: number
      lastExecution: string
    }> = []

    for (const [queryName, metrics] of this.metrics.entries()) {
      results.push({
        queryName,
        avgTime: Math.round(metrics.totalTime / metrics.count),
        totalQueries: metrics.count,
        errorRate: (metrics.errors / metrics.count) * 100,
        lastExecution: new Date(metrics.lastExecution).toISOString()
      })
    }

    return results.sort((a, b) => b.avgTime - a.avgTime)
  }
}

// ä¼˜åŒ–çš„æ•°æ®åº“æ“ä½œç±»
export class DatabaseOptimizer {
  private cache = getCache()

  // å¸¦ç¼“å­˜çš„æŸ¥è¯¢
  async cachedQuery<T>(
    queryName: string,
    queryFn: () => Promise<T>,
    cacheKey: string,
    ttl: number = 300 // 5åˆ†é’Ÿé»˜è®¤ç¼“å­˜
  ): Promise<T> {
    const startTime = Date.now()
    
    try {
      // å°è¯•ä»ç¼“å­˜è·å–
      const cached = await this.cache.get(cacheKey)
      if (cached) {
        try {
          const result = JSON.parse(cached)
          QueryPerformanceMonitor.recordQuery(`${queryName}:cache`, Date.now() - startTime, true)
          return result
        } catch (error) {
          console.warn('ç¼“å­˜è§£æå¤±è´¥:', error)
        }
      }

      // æ‰§è¡ŒæŸ¥è¯¢
      const result = await queryFn()
      
      // ç¼“å­˜ç»“æœ
      if (result !== null && result !== undefined) {
        try {
          await this.cache.set(cacheKey, JSON.stringify(result), ttl)
        } catch (error) {
          console.warn('ç¼“å­˜è®¾ç½®å¤±è´¥:', error)
        }
      }

      QueryPerformanceMonitor.recordQuery(queryName, Date.now() - startTime, true)
      return result
    } catch (error) {
      QueryPerformanceMonitor.recordQuery(queryName, Date.now() - startTime, false)
      throw error
    }
  }

  // æ‰¹é‡æ’å…¥ä¼˜åŒ–
  async batchInsert<T>(
    table: string,
    data: T[],
    batchSize: number = 100
  ): Promise<T[]> {
    const startTime = Date.now()
    const results: T[] = []
    
    try {
      // åˆ†æ‰¹å¤„ç†
      for (let i = 0; i < data.length; i += batchSize) {
        const batch = data.slice(i, i + batchSize)
        
        const { data: batchResult, error } = await supabaseAdmin
          .from(table)
          .insert(batch)
          .select()
        
        if (error) {
          console.error(`æ‰¹é‡æ’å…¥å¤±è´¥ (batch ${Math.floor(i / batchSize) + 1}):`, error)
          throw error
        }
        
        if (batchResult) {
          results.push(...batchResult)
        }
      }

      QueryPerformanceMonitor.recordQuery(`batchInsert:${table}`, Date.now() - startTime, true)
      return results
    } catch (error) {
      QueryPerformanceMonitor.recordQuery(`batchInsert:${table}`, Date.now() - startTime, false)
      throw error
    }
  }

  // æ‰¹é‡æ›´æ–°ä¼˜åŒ–
  async batchUpdate<T>(
    table: string,
    updates: Array<{ id: string; data: Partial<T> }>,
    batchSize: number = 50
  ): Promise<void> {
    const startTime = Date.now()
    
    try {
      // åˆ†æ‰¹å¤„ç†æ›´æ–°
      for (let i = 0; i < updates.length; i += batchSize) {
        const batch = updates.slice(i, i + batchSize)
        
        // å¹¶è¡Œæ‰§è¡Œæ‰¹æ¬¡å†…çš„æ›´æ–°
        const promises = batch.map(({ id, data }) =>
          supabaseAdmin
            .from(table)
            .update(data)
            .eq('id', id)
        )
        
        const results = await Promise.allSettled(promises)
        
        // æ£€æŸ¥å¤±è´¥çš„æ›´æ–°
        const failures = results.filter(result => result.status === 'rejected')
        if (failures.length > 0) {
          console.warn(`æ‰¹é‡æ›´æ–°éƒ¨åˆ†å¤±è´¥: ${failures.length}/${batch.length}`)
        }
      }

      QueryPerformanceMonitor.recordQuery(`batchUpdate:${table}`, Date.now() - startTime, true)
    } catch (error) {
      QueryPerformanceMonitor.recordQuery(`batchUpdate:${table}`, Date.now() - startTime, false)
      throw error
    }
  }

  // ä¼˜åŒ–çš„ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡æŸ¥è¯¢
  async getUserUsageOptimized(userId: string) {
    return this.cachedQuery(
      'getUserUsage',
      async () => {
        const { data, error } = await supabaseAdmin
          .from('user_usage')
          .select('*')
          .eq('user_id', userId)
          .single()
        
        if (error) throw error
        return data
      },
      `user_usage:${userId}`,
      60 // 1åˆ†é’Ÿç¼“å­˜
    )
  }

  // ä¼˜åŒ–çš„ç”¨æˆ·å‘½ç›˜æŸ¥è¯¢
  async getUserChartsOptimized(userId: string, limit: number = 20) {
    return this.cachedQuery(
      'getUserCharts',
      async () => {
        const { data, error } = await supabaseAdmin
          .from('user_charts')
          .select('id, name, birth_year, birth_month, birth_day, chart_type, category, created_at')
          .eq('user_id', userId)
          .order('created_at', { ascending: false })
          .limit(limit)
        
        if (error) throw error
        return data
      },
      `user_charts:${userId}:${limit}`,
      300 // 5åˆ†é’Ÿç¼“å­˜
    )
  }

  // ä¼˜åŒ–çš„AIåˆ†ææŸ¥è¯¢
  async getAnalysisTasksOptimized(
    userId: string, 
    status?: string, 
    limit: number = 10
  ) {
    const cacheKey = `analysis_tasks:${userId}:${status || 'all'}:${limit}`
    
    return this.cachedQuery(
      'getAnalysisTasks',
      async () => {
        let query = supabaseAdmin
          .from('analysis_tasks')
          .select('id, task_type, status, created_at, completed_at')
          .eq('user_id', userId)
          .order('created_at', { ascending: false })
          .limit(limit)
        
        if (status) {
          query = query.eq('status', status)
        }
        
        const { data, error } = await query
        if (error) throw error
        return data
      },
      cacheKey,
      180 // 3åˆ†é’Ÿç¼“å­˜
    )
  }

  // æ™ºèƒ½åˆ†é¡µæŸ¥è¯¢
  async paginatedQuery<T>(
    table: string,
    options: {
      userId?: string
      filters?: Record<string, any>
      orderBy?: string
      ascending?: boolean
      page: number
      limit: number
      select?: string
    }
  ): Promise<{
    data: T[]
    total: number
    hasMore: boolean
    nextPage: number | null
  }> {
    const { userId, filters, orderBy = 'created_at', ascending = false, page, limit, select = '*' } = options
    const offset = (page - 1) * limit
    
    const startTime = Date.now()
    
    try {
      // æ„å»ºæŸ¥è¯¢
      let query = supabaseAdmin
        .from(table)
        .select(select, { count: 'exact' })
      
      if (userId) {
        query = query.eq('user_id', userId)
      }
      
      if (filters) {
        Object.entries(filters).forEach(([key, value]) => {
          query = query.eq(key, value)
        })
      }
      
      query = query
        .order(orderBy, { ascending })
        .range(offset, offset + limit - 1)
      
      const { data, error, count } = await query
      
      if (error) throw error
      
      const total = count || 0
      const hasMore = offset + limit < total
      const nextPage = hasMore ? page + 1 : null
      
      QueryPerformanceMonitor.recordQuery(`paginatedQuery:${table}`, Date.now() - startTime, true)
      
      return {
        data: data || [],
        total,
        hasMore,
        nextPage
      }
    } catch (error) {
      QueryPerformanceMonitor.recordQuery(`paginatedQuery:${table}`, Date.now() - startTime, false)
      throw error
    }
  }

  // ç¼“å­˜å¤±æ•ˆ
  async invalidateCache(pattern: string) {
    try {
      // è¿™é‡Œå¯ä»¥å®ç°æ¨¡å¼åŒ¹é…çš„ç¼“å­˜åˆ é™¤
      // ç®€åŒ–ç‰ˆæœ¬ï¼šåˆ é™¤ç‰¹å®šé”®
      await this.cache.del(pattern)
    } catch (error) {
      console.warn('ç¼“å­˜å¤±æ•ˆå¤±è´¥:', error)
    }
  }

  // æ‰¹é‡ç¼“å­˜å¤±æ•ˆ
  async invalidateCachesBatch(patterns: string[]) {
    try {
      await Promise.all(patterns.map(pattern => this.invalidateCache(pattern)))
    } catch (error) {
      console.warn('æ‰¹é‡ç¼“å­˜å¤±æ•ˆå¤±è´¥:', error)
    }
  }

  // é¢„çƒ­ç¼“å­˜
  async warmupCache(userId: string) {
    try {
      // é¢„åŠ è½½å¸¸ç”¨æ•°æ®
      await Promise.all([
        this.getUserUsageOptimized(userId),
        this.getUserChartsOptimized(userId, 10),
        this.getAnalysisTasksOptimized(userId, 'completed', 5)
      ])
      console.log(`âœ… ç”¨æˆ·ç¼“å­˜é¢„çƒ­å®Œæˆ: ${userId}`)
    } catch (error) {
      console.warn('ç¼“å­˜é¢„çƒ­å¤±è´¥:', error)
    }
  }

  // æ•°æ®åº“å¥åº·æ£€æŸ¥
  async healthCheck(): Promise<{
    status: 'healthy' | 'degraded' | 'unhealthy'
    metrics: any
    recommendations: string[]
  }> {
    const startTime = Date.now()
    const recommendations: string[] = []
    
    try {
      // ç®€å•æŸ¥è¯¢æµ‹è¯•
      const { error } = await supabaseAdmin
        .from('users')
        .select('id')
        .limit(1)
      
      if (error) {
        return {
          status: 'unhealthy',
          metrics: { responseTime: Date.now() - startTime },
          recommendations: ['æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œé…ç½®']
        }
      }

      const responseTime = Date.now() - startTime
      const performanceMetrics = QueryPerformanceMonitor.getMetrics()
      
      // æ€§èƒ½è¯„ä¼°
      let status: 'healthy' | 'degraded' | 'unhealthy' = 'healthy'
      
      if (responseTime > 1000) {
        status = 'degraded'
        recommendations.push('æ•°æ®åº“å“åº”æ—¶é—´è¾ƒæ…¢ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥')
      }
      
      const slowQueries = performanceMetrics.filter(m => m.avgTime > 2000)
      if (slowQueries.length > 0) {
        status = 'degraded'
        recommendations.push(`å‘ç°${slowQueries.length}ä¸ªæ…¢æŸ¥è¯¢ï¼Œå»ºè®®ä¼˜åŒ–`)
      }
      
      const highErrorRateQueries = performanceMetrics.filter(m => m.errorRate > 5)
      if (highErrorRateQueries.length > 0) {
        status = 'degraded'
        recommendations.push(`å‘ç°${highErrorRateQueries.length}ä¸ªé«˜é”™è¯¯ç‡æŸ¥è¯¢`)
      }

      return {
        status,
        metrics: {
          responseTime,
          totalQueries: performanceMetrics.reduce((sum, m) => sum + m.totalQueries, 0),
          avgResponseTime: performanceMetrics.reduce((sum, m) => sum + m.avgTime, 0) / performanceMetrics.length || 0,
          slowQueries: slowQueries.length,
          highErrorRateQueries: highErrorRateQueries.length
        },
        recommendations
      }
    } catch (error) {
      return {
        status: 'unhealthy',
        metrics: { error: String(error) },
        recommendations: ['æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜']
      }
    }
  }
}

// å•ä¾‹å®ä¾‹
export const dbOptimizer = new DatabaseOptimizer()

// å¯¼å‡ºæ€§èƒ½ç›‘æ§
 